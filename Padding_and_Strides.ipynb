{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fahriyegrl/ds-677-deep-learning/blob/main/Padding_and_Strides.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 2,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzW6BBpuplq3",
        "outputId": "877663dd-12cc-473a-a1fb-ca194fe42532"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# We define a convenience function to calculate the convolutional layer. This\n",
        "# function initializes the convolutional layer weights and performs\n",
        "# corresponding dimensionality elevations and reductions on the input and\n",
        "# output\n",
        "def comp_conv2d(conv2d, X):\n",
        "    # Here (1, 1) indicates that the batch size and the number of channels\n",
        "    # are both 1\n",
        "    X = X.reshape((1, 1) + X.shape)\n",
        "    Y = conv2d(X)\n",
        "    # Exclude the first two dimensions that do not interest us: examples and\n",
        "    # channels\n",
        "    return Y.reshape(Y.shape[2:])\n",
        "# Note that here 1 row or column is padded on either side, so a total of 2\n",
        "# rows or columns are added\n",
        "conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1)\n",
        "X = torch.rand(size=(8, 8))\n",
        "comp_conv2d(conv2d, X).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 4,
        "id": "Y0pyBn2jplq5"
      },
      "source": [
        "When the height and width of the convolution kernel are different,\n",
        "we can make the output and input have the same height and width\n",
        "by setting different padding numbers for height and width.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 6,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhDzxsOTplq6",
        "outputId": "89716195-56a3-4224-a06d-83f7429431c8"
      },
      "source": [
        "# Here, we use a convolution kernel with a height of 5 and a width of 3. The\n",
        "# padding numbers on either side of the height and width are 2 and 1,\n",
        "# respectively\n",
        "conv2d = nn.Conv2d(1, 1, kernel_size=(5, 3), padding=(2, 1))\n",
        "comp_conv2d(conv2d, X).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 10,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5az8Vg5jplq7",
        "outputId": "3bdb70c5-5421-4a83-a755-3e5e62cf9879"
      },
      "source": [
        "conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1, stride=2)\n",
        "comp_conv2d(conv2d, X).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 12,
        "id": "LLV1aogZplq7"
      },
      "source": [
        "Next, we will look at a slightly more complicated example.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 14,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBm52sAyplq7",
        "outputId": "7caacdc7-fc35-431e-a2f1-a8bcd8d568af"
      },
      "source": [
        "conv2d = nn.Conv2d(1, 1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))\n",
        "comp_conv2d(conv2d, X).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    }
  ]
}